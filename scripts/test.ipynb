{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'ct-clip (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from vit_3d import ViT\n",
    "\n",
    "import torch \n",
    "\n",
    "image_encoder = ViT(\n",
    "            image_size = 256,          # image size\n",
    "            frames = 512,               # max number of frames\n",
    "            image_patch_size = 32,     # image patch size\n",
    "            frame_patch_size = 4,      # frame patch size\n",
    "            dim = 768,\n",
    "            depth = 12,\n",
    "            heads = 8,\n",
    "            mlp_dim = 2048,\n",
    "            channels=1,\n",
    "            dropout = 0.1,\n",
    "            emb_dropout = 0.1\n",
    "        )\n",
    "\n",
    "video = torch.randn(1, 1, 256, 256, 156)\n",
    "\n",
    "video_encoding, pos = image_encoder(video) # (1, 512, 768)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 768])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# video = torch.randn(8, 1, 512, 512, 8)\n",
    "\n",
    "# video_encoding, pos = image_encoder(video) \n",
    "video_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "T = video_encoding.shape[1]\n",
    "# ([8, 512, 768]) --> [8, 2, 256, 768]\n",
    "video_encoding = rearrange(video_encoding, 'b (t f) d -> b t f d', f=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 64, 768]), 49152)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_encoding.shape, 64 * 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda3/envs/BBDM/lib/python3.9/site-packages/torch/nn/modules/conv.py:608: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv3d(\n"
     ]
    }
   ],
   "source": [
    "from ctvit import CTViT\n",
    "\n",
    "image_encoder1 = CTViT(\n",
    "    dim = 512,\n",
    "    codebook_size = 8192,\n",
    "    image_size = 480,\n",
    "    patch_size = 20,\n",
    "    temporal_patch_size = 10,\n",
    "    spatial_depth = 4,\n",
    "    temporal_depth = 4,\n",
    "    dim_head = 32,\n",
    "    heads = 8\n",
    ").to('cuda')\n",
    "video = torch.randn(8, 1, 30, 480, 480).to('cuda')\n",
    "tokens = image_encoder1(video, return_encoded_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = torch.randn(8, 1, 40, 480, 480).to('cuda')\n",
    "tokens = image_encoder1(video, return_encoded_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 24, 24, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294912"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24 * 24 * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './DAC001'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./DAC001\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your actual root folder path\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create datasets for different splits.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMedicalImageReportDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m val_dataset   \u001b[38;5;241m=\u001b[39m MedicalImageReportDataset(root\u001b[38;5;241m=\u001b[39mroot_dir, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m test_dataset  \u001b[38;5;241m=\u001b[39m MedicalImageReportDataset(root\u001b[38;5;241m=\u001b[39mroot_dir, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/home/huutien/CT-CLIP/scripts/data_new.py:23\u001b[0m, in \u001b[0;36mMedicalImageReportDataset.__init__\u001b[0;34m(self, root, split, transform)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Determine which month folders to include based on the split.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonth_folders \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     24\u001b[0m     month_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, month)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(month_path):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './DAC001'"
     ]
    }
   ],
   "source": [
    "\n",
    "root_dir = \"./DAC001\"  # Replace with your actual root folder path\n",
    "\n",
    "# Create datasets for different splits.\n",
    "train_dataset = MedicalImageReportDataset(root=root_dir, split='train')\n",
    "val_dataset   = MedicalImageReportDataset(root=root_dir, split='val')\n",
    "test_dataset  = MedicalImageReportDataset(root=root_dir, split='test')\n",
    "\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of validation samples:\", len(val_dataset))\n",
    "print(\"Number of test samples:\", len(test_dataset))\n",
    "\n",
    "# Display a sample\n",
    "image, report = train_dataset[0]\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Report content:\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting monai\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x155552e7cef0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /packages/79/86/8bf48a306e3ad9de54a9c2e08c99eb52d528455ed9a757403bcd54d714f9/monai-1.4.0-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x155552e7d040>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /packages/79/86/8bf48a306e3ad9de54a9c2e08c99eb52d528455ed9a757403bcd54d714f9/monai-1.4.0-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy<2.0,>=1.24 (from monai)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: torch>=1.9 in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from monai) (2.4.0)\n",
      "Requirement already satisfied: filelock in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from torch>=1.9->monai) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from torch>=1.9->monai) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from torch>=1.9->monai) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from torch>=1.9->monai) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from torch>=1.9->monai) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from torch>=1.9->monai) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from torch>=1.9->monai) (75.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
      "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, monai\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.1\n",
      "    Uninstalling numpy-2.2.1:\n",
      "      Successfully uninstalled numpy-2.2.1\n",
      "Successfully installed monai-1.4.0 numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/miniconda3/envs/thaind/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading dataset:  25%|██▍       | 743/2988 [02:17<16:02,  2.33it/s]  "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from monai.data import CacheDataset\n",
    "import torch\n",
    "from monai.transforms import LoadImaged\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class PetReportPairDataset(CacheDataset):\n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 split='train', \n",
    "                 transform=LoadImaged(\"image\"), \n",
    "                 cache_num=sys.maxsize,\n",
    "                 cache_rate=1.0,\n",
    "                 num_workers=4,):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): Path to the root folder (e.g., \"./DAC001\").\n",
    "            split (str): One of 'train', 'val', or 'test'.\n",
    "                - train: use all month folders except THANG 10, THANG 11, THANG 12.\n",
    "                - val: use only THANG 10.\n",
    "                - test: use only THANG 11 and THANG 12.\n",
    "            transform: Optional transform to be applied on a sample (e.g., conversion to torch tensor, normalization, etc.).\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.split = split.lower()\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Determine which month folders to include based on the split.\n",
    "        self.month_folders = []\n",
    "        for month in os.listdir(root):\n",
    "            month_path = os.path.join(root, month)\n",
    "            if not os.path.isdir(month_path):\n",
    "                continue\n",
    "            if self.split == 'train':\n",
    "                if month in ['THANG 10', 'THANG 11', 'THANG 12']:\n",
    "                    continue\n",
    "                else:\n",
    "                    self.month_folders.append(month_path)\n",
    "            elif self.split == 'val':\n",
    "                if month == 'THANG 10':\n",
    "                    self.month_folders.append(month_path)\n",
    "            elif self.split == 'test':\n",
    "                if month in ['THANG 11', 'THANG 12']:\n",
    "                    self.month_folders.append(month_path)\n",
    "        \n",
    "        # Allowed modalities (exclude \"whole_body\")\n",
    "        allowed_modalities = ['abdomen_pelvis', 'chest', 'head_neck']\n",
    "        \n",
    "        # Build the list of (image_path, report_path) pairs.\n",
    "        self.datalist = []\n",
    "        for month_folder in self.month_folders:\n",
    "            images_root = os.path.join(month_folder, 'images')\n",
    "            reports_root = os.path.join(month_folder, 'reports')\n",
    "            if not os.path.isdir(images_root) or not os.path.isdir(reports_root):\n",
    "                continue\n",
    "            for modality in allowed_modalities:\n",
    "                modality_img_folder = os.path.join(images_root, modality)\n",
    "                modality_rep_folder = os.path.join(reports_root, modality)\n",
    "                if not os.path.isdir(modality_img_folder) or not os.path.isdir(modality_rep_folder):\n",
    "                    continue\n",
    "                # List all image files ending with .npy\n",
    "                image_files = sorted([f for f in os.listdir(modality_img_folder) if f.endswith('.npy')])\n",
    "                for img_file in image_files:\n",
    "                    base_name = os.path.splitext(img_file)[0]\n",
    "                    rep_file = base_name + '.txt'\n",
    "                    img_file_path = os.path.join(modality_img_folder, img_file)\n",
    "                    rep_file_path = os.path.join(modality_rep_folder, rep_file)\n",
    "                    if os.path.exists(rep_file_path):\n",
    "                        self.datalist.append({\"image\": img_file_path, \"label\": rep_file_path})\n",
    "        \n",
    "        super().__init__(\n",
    "            data=self.datalist,\n",
    "            transform=self.transform,\n",
    "            cache_num=cache_num,\n",
    "            cache_rate=cache_rate,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load sample\n",
    "        sample = self.datalist[index]\n",
    "        image_path = sample['image']\n",
    "        report_path = sample['label']\n",
    "\n",
    "        # Load the image data\n",
    "        image = np.load(image_path)\n",
    "        \n",
    "        # Padding depth to be divisible by 4\n",
    "        depth = image.shape[0]\n",
    "        if depth % 4 != 0:\n",
    "            padding_needed = 4 - (depth % 4)\n",
    "            image = np.pad(image, ((0, padding_needed), (0, 0), (0, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "        # Normalize image to range [-1, 1]\n",
    "        image = image.astype(np.float32)  # Ensure float32 for the normalization\n",
    "        image = (image - 400) / 600  # Normalize to [0, 1]\n",
    "        image = 2 * image - 1  # Scale to [-1, 1]\n",
    "\n",
    "        # Apply the transform (e.g., to tensor, resize, etc.)\n",
    "        if self.transform:\n",
    "            image = self.transform({\"image\": image})['image']\n",
    "\n",
    "        # Load the report text\n",
    "        with open(report_path, 'r', encoding='utf-8') as file:\n",
    "            report_text = file.read().strip()\n",
    "\n",
    "        return image, report_text\n",
    "\n",
    "# Example usage:\n",
    "# if __name__ == '__main__':\n",
    "data_folder = \"/home/user01/aiotlab/thaind/DAC001\"  # Path to your root folder\n",
    "dataset = PetReportPairDataset(root=data_folder, split='train', transform=LoadImaged(\"image\"))\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "\n",
    "# Fetch and display one sample\n",
    "image, report = dataset[0]\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Report text:\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Định nghĩa đường dẫn tới dataset\n",
    "DATASET_PATH = \"/home/user01/aiotlab/thaind/DAC001\"\n",
    "\n",
    "# Các bộ phận cần thống kê\n",
    "BODY_PARTS = [\"abdomen_pelvis\", \"chest\", \"head_neck\"]\n",
    "\n",
    "# Dictionary để lưu thống kê độ sâu\n",
    "depth_stats = {part: [] for part in BODY_PARTS}\n",
    "depth_stats[\"all\"] = []  # Thống kê toàn bộ dataset\n",
    "\n",
    "# Duyệt qua từng tháng trong dataset\n",
    "for month in os.listdir(DATASET_PATH):\n",
    "    month_path = os.path.join(DATASET_PATH, month)\n",
    "    \n",
    "    if not os.path.isdir(month_path):\n",
    "        continue  # Bỏ qua nếu không phải thư mục\n",
    "    \n",
    "    images_path = os.path.join(month_path, \"images\")\n",
    "    \n",
    "    if not os.path.isdir(images_path):\n",
    "        continue  # Bỏ qua nếu không có thư mục hình ảnh\n",
    "    \n",
    "    # Duyệt qua từng bộ phận\n",
    "    for part in BODY_PARTS:\n",
    "        part_path = os.path.join(images_path, part)\n",
    "        \n",
    "        if not os.path.isdir(part_path):\n",
    "            continue  # Bỏ qua nếu thư mục không tồn tại\n",
    "        \n",
    "        # Duyệt qua tất cả các file .npy\n",
    "        for file in os.listdir(part_path):\n",
    "            if file.endswith(\".npy\"):\n",
    "                file_path = os.path.join(part_path, file)\n",
    "                \n",
    "                # Load file npy và lấy độ sâu\n",
    "                try:\n",
    "                    image = np.load(file_path)\n",
    "                    depth = image.shape[0]  # Lấy kích thước chiều sâu\n",
    "                    depth_stats[part].append(depth)\n",
    "                    depth_stats[\"all\"].append(depth)  # Lưu vào thống kê toàn bộ dataset\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi khi đọc {file_path}: {e}\")\n",
    "\n",
    "# Hàm tính toán thống kê cơ bản\n",
    "def compute_statistics(depth_list):\n",
    "    if not depth_list:\n",
    "        return {\"min\": None, \"max\": None, \"mean\": None, \"std\": None, \"count\": 0}\n",
    "    \n",
    "    return {\n",
    "        \"min\": np.min(depth_list),\n",
    "        \"max\": np.max(depth_list),\n",
    "        \"mean\": np.mean(depth_list),\n",
    "        \"std\": np.std(depth_list),\n",
    "        \"count\": len(depth_list)\n",
    "    }\n",
    "\n",
    "# Tạo DataFrame để hiển thị kết quả\n",
    "stats_summary = {part: compute_statistics(depth_stats[part]) for part in depth_stats}\n",
    "df_stats = pd.DataFrame(stats_summary).T\n",
    "\n",
    "# Hiển thị thống kê\n",
    "# import ace_tools as tools  # Sử dụng công cụ hiển thị DataFrame\n",
    "# tools.display_dataframe_to_user(name=\"Dataset Depth Statistics\", dataframe=df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abdomen_pelvis</th>\n",
       "      <td>69.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>155.817696</td>\n",
       "      <td>15.757686</td>\n",
       "      <td>1311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>142.905199</td>\n",
       "      <td>10.534502</td>\n",
       "      <td>1308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head_neck</th>\n",
       "      <td>50.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>98.756674</td>\n",
       "      <td>8.605844</td>\n",
       "      <td>1311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>1.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>132.485242</td>\n",
       "      <td>27.234360</td>\n",
       "      <td>3930.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 min    max        mean        std   count\n",
       "abdomen_pelvis  69.0  268.0  155.817696  15.757686  1311.0\n",
       "chest            1.0  218.0  142.905199  10.534502  1308.0\n",
       "head_neck       50.0  161.0   98.756674   8.605844  1311.0\n",
       "all              1.0  268.0  132.485242  27.234360  3930.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Các file head_neck có hơn 110 lát cắt:\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 3/images/whole_body/day_8_patient_317.npy - Slices: 199\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 2/images/whole_body/day_24_patient_112.npy - Slices: 191\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 12/images/whole_body/day_19_patient_1609.npy - Slices: 173\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 4/images/whole_body/day_27_patient_458.npy - Slices: 89\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 4/images/whole_body/day_25_patient_432.npy - Slices: 89\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 7/images/whole_body/day_6_patient_1012.npy - Slices: 89\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 9/images/whole_body/day_28_patient_1191.npy - Slices: 83\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 11/images/whole_body/day_21_patient_1472.npy - Slices: 199\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Định nghĩa đường dẫn tới dataset\n",
    "DATASET_PATH = \"/home/user01/aiotlab/thaind/DAC001\"\n",
    "\n",
    "# Bộ phận cần lọc\n",
    "TARGET_PART = \"whole_body\"\n",
    "\n",
    "# Danh sách lưu các tệp có hơn 100 slices\n",
    "large_slices_files = []\n",
    "\n",
    "# Duyệt qua từng tháng trong dataset\n",
    "for month in os.listdir(DATASET_PATH):\n",
    "    month_path = os.path.join(DATASET_PATH, month)\n",
    "\n",
    "    if not os.path.isdir(month_path):\n",
    "        continue  # Bỏ qua nếu không phải thư mục\n",
    "    \n",
    "    images_path = os.path.join(month_path, \"images\")\n",
    "    part_path = os.path.join(images_path, TARGET_PART)\n",
    "\n",
    "    if not os.path.isdir(part_path):\n",
    "        continue  # Bỏ qua nếu thư mục không tồn tại\n",
    "    \n",
    "    # Duyệt qua tất cả các file .npy trong thư mục head_neck\n",
    "    for file in os.listdir(part_path):\n",
    "        if file.endswith(\".npy\"):\n",
    "            file_path = os.path.join(part_path, file)\n",
    "\n",
    "            # Load file npy và lấy số lát cắt (depth)\n",
    "            try:\n",
    "                image = np.load(file_path)\n",
    "                depth = image.shape[0]  # Lấy kích thước chiều sâu (số lát cắt)\n",
    "\n",
    "                if depth < 200:\n",
    "                    large_slices_files.append((file_path, depth))  # Lưu lại đường dẫn và depth\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi đọc {file_path}: {e}\")\n",
    "\n",
    "# In danh sách các file có hơn 100 lát cắt\n",
    "if large_slices_files:\n",
    "    print(\"\\n🔍 Các file head_neck có hơn 110 lát cắt:\")\n",
    "    for path, depth in large_slices_files:\n",
    "        print(f\"{path} - Slices: {depth}\")\n",
    "else:\n",
    "    print(\"✅ Không có file head_neck nào có hơn 100 lát cắt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗑️ Các file đã xóa:\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 3/images/abdomen_pelvis/day_8_patient_317.npy\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 2/images/abdomen_pelvis/day_24_patient_112.npy\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 12/images/abdomen_pelvis/day_19_patient_1609.npy\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 4/images/abdomen_pelvis/day_27_patient_458.npy\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 4/images/abdomen_pelvis/day_25_patient_432.npy\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 7/images/abdomen_pelvis/day_6_patient_1012.npy\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 9/images/abdomen_pelvis/day_28_patient_1191.npy\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 11/images/abdomen_pelvis/day_21_patient_1472.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Danh sách các phần cơ thể cần xóa\n",
    "TARGET_PARTS = [\"whole_body\", \"head_neck\", \"chest\", \"abdomen_pelvis\"]\n",
    "\n",
    "# Danh sách file cần xóa (bạn có thể đọc từ file hoặc liệt kê trực tiếp)\n",
    "files_to_delete = [\n",
    "    \"/home/user01/aiotlab/thaind/DAC001/THANG 3/images/abdomen_pelvis/day_8_patient_317.npy\",\n",
    "    \"/home/user01/aiotlab/thaind/DAC001/THANG 2/images/abdomen_pelvis/day_24_patient_112.npy\",\n",
    "    \"/home/user01/aiotlab/thaind/DAC001/THANG 12/images/abdomen_pelvis/day_19_patient_1609.npy\",\n",
    "    \"/home/user01/aiotlab/thaind/DAC001/THANG 4/images/abdomen_pelvis/day_27_patient_458.npy\",\n",
    "    \"/home/user01/aiotlab/thaind/DAC001/THANG 4/images/abdomen_pelvis/day_25_patient_432.npy\",\n",
    "    \"/home/user01/aiotlab/thaind/DAC001/THANG 7/images/abdomen_pelvis/day_6_patient_1012.npy\",\n",
    "    \"/home/user01/aiotlab/thaind/DAC001/THANG 9/images/abdomen_pelvis/day_28_patient_1191.npy\",\n",
    "    \"/home/user01/aiotlab/thaind/DAC001/THANG 11/images/abdomen_pelvis/day_21_patient_1472.npy\",\n",
    "]\n",
    "\n",
    "# Kiểm tra và xóa các file thuộc TARGET_PARTS\n",
    "deleted_files = []\n",
    "not_found_files = []\n",
    "\n",
    "for file_path in files_to_delete:\n",
    "    # Kiểm tra xem file có thuộc TARGET_PARTS không\n",
    "    if any(part in file_path for part in TARGET_PARTS):\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                os.remove(file_path)  # Xóa file\n",
    "                deleted_files.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Lỗi khi xóa {file_path}: {e}\")\n",
    "        else:\n",
    "            not_found_files.append(file_path)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "if deleted_files:\n",
    "    print(\"\\n🗑️ Các file đã xóa:\")\n",
    "    for file in deleted_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"✅ Không có file nào để xóa.\")\n",
    "\n",
    "if not_found_files:\n",
    "    print(\"\\n⚠️ Các file không tìm thấy (có thể đã bị xóa trước đó):\")\n",
    "    for file in not_found_files:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515, 256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '/home/user01/aiotlab/thaind/DAC001/THANG 9/images/whole_body/day_28_patient_1191.npy'\n",
    "path = '/home/user01/aiotlab/thaind/DAC001/THANG 12/images/whole_body/day_6_patient_1685.npy'\n",
    "check = np.load(path)\n",
    "\n",
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Các file có Depth = 1:\n",
      "/home/user01/aiotlab/thaind/DAC001/THANG 9/images/chest/day_28_patient_1191.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Định nghĩa đường dẫn tới dataset\n",
    "DATASET_PATH = \"/home/user01/aiotlab/thaind/DAC001\"\n",
    "\n",
    "# Các bộ phận cần kiểm tra\n",
    "BODY_PARTS = [\"abdomen_pelvis\", \"chest\", \"head_neck\"]\n",
    "\n",
    "# Danh sách lưu các tệp có depth = 1\n",
    "depth_1_files = []\n",
    "\n",
    "# Duyệt qua từng tháng trong dataset\n",
    "for month in os.listdir(DATASET_PATH):\n",
    "    month_path = os.path.join(DATASET_PATH, month)\n",
    "\n",
    "    if not os.path.isdir(month_path):\n",
    "        continue  # Bỏ qua nếu không phải thư mục\n",
    "    \n",
    "    images_path = os.path.join(month_path, \"images\")\n",
    "\n",
    "    if not os.path.isdir(images_path):\n",
    "        continue  # Bỏ qua nếu không có thư mục hình ảnh\n",
    "    \n",
    "    # Duyệt qua từng bộ phận\n",
    "    for part in BODY_PARTS:\n",
    "        part_path = os.path.join(images_path, part)\n",
    "\n",
    "        if not os.path.isdir(part_path):\n",
    "            continue  # Bỏ qua nếu thư mục không tồn tại\n",
    "        \n",
    "        # Duyệt qua tất cả các file .npy\n",
    "        for file in os.listdir(part_path):\n",
    "            if file.endswith(\".npy\"):\n",
    "                file_path = os.path.join(part_path, file)\n",
    "\n",
    "                # Load file npy và lấy độ sâu\n",
    "                try:\n",
    "                    image = np.load(file_path)\n",
    "                    depth = image.shape[0]  # Lấy kích thước chiều sâu\n",
    "\n",
    "                    if depth == 1:\n",
    "                        depth_1_files.append(file_path)  # Lưu lại đường dẫn\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi khi đọc {file_path}: {e}\")\n",
    "\n",
    "# In danh sách các file có Depth = 1\n",
    "if depth_1_files:\n",
    "    print(\"\\n🔍 Các file có Depth = 1:\")\n",
    "    for path in depth_1_files:\n",
    "        print(path)\n",
    "else:\n",
    "    print(\"✅ Không có file nào có Depth = 1.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thaind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
